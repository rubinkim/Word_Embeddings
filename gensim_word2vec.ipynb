{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re    # for preprocessing\n",
    "import pandas as pd    # for data handling\n",
    "from time import time    # to time our operations\n",
    "from collections import defaultdict    # for word frequency\n",
    "\n",
    "import spacy    # for preprocessing\n",
    "\n",
    "import logging    # setting up the loggings to mointor gensim\n",
    "# Define the format of the log message. It includes log level, timestamp, and the actual log message\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt='%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158314, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/simpsons_dataset.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158314,\n",
       " array([\"No, actually, it was a little of both. Sometimes when a disease is in all the magazines and all the news shows, it's only natural that you think you have it.\",\n",
       "        \"Where's Mr. Bergstrom?\",\n",
       "        \"I don't know. Although I'd sure like to talk to him. He didn't touch my lesson plan. What did he teach you?\",\n",
       "        ..., 'Psy-cho-so-ma-tic.', 'Does that mean you were crazy?',\n",
       "        'No, that means she was faking it.'], dtype=object))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['spoken_words'].values), df['spoken_words'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_character_text    17814\n",
      "spoken_words          26459\n",
      "dtype: int64\n",
      "(131853, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check how many lines are null\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# remove null values\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In spaCy, a pipeline refers to a series of processing components that are applied to a text document sequentially. \n",
    "# Each component in the pipeline performs a specific task, such as tokenization, part-of-speech tagging, syntactic parsing, named entity recognition, and so on. \n",
    "# The output of one component serves as the input to the next component in the pipeline.\n",
    "# When you load a spaCy model, it comes with a default pipeline of processing components that are applied to the text. \n",
    "# However, you can customize the pipeline by adding, removing, or modifying the components according to your specific requirements.\n",
    "# The pipeline in spaCy is designed to be efficient and allows for fast processing of large volumes of text. \n",
    "# It takes advantage of the processing capabilities of spaCy's underlying machine learning models and linguistic data structures.\n",
    "# You can access the current pipeline components of a loaded spaCy model using the nlp.pipe_names attribute. \n",
    "# Similarly, you can add or modify components in the pipeline using the nlp.add_pipe() or nlp.remove_pipe() methods respectively.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I\n",
      "am be\n",
      "running run\n",
      "along along\n",
      "Tancheon Tancheon\n",
      "which which\n",
      "is be\n",
      "a a\n",
      "small small\n",
      "and and\n",
      "narrow narrow\n",
      "river river\n",
      "for for\n",
      "about about\n",
      "two two\n",
      "hours hour\n",
      "everyday everyday\n",
      ", ,\n",
      "praying pray\n",
      "Christ Christ\n",
      "Jesus Jesus\n",
      "to to\n",
      "work work\n",
      "inside inside\n",
      "me I\n",
      "and and\n",
      "help help\n",
      "recover recover\n",
      "from from\n",
      "my my\n",
      "illness illness\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "# Spacy is a popular Python library used for natural language processing (NLP) tasks. \n",
    "# It provides a lemmatization module that allows you to convert words to their base or dictionary form, known as lemmas. \n",
    "# The Spacy lemmatizer is built on linguistic rules and utilizes contextual information to determine the appropriate lemma for a given word.\n",
    "# Here's an example of how to use spaCy's lemmatizer\n",
    "import spacy\n",
    "nlp = spacy.load(name='en_core_web_sm')      # Load the English Language Model\n",
    "txt = \"I am running along Tancheon which is a small and narrow river for about two hours everyday, praying Christ Jesus to work inside me and help recover from my illness.\"\n",
    "\n",
    "# Tokenize text into individual words\n",
    "doc = nlp(txt)\n",
    "\n",
    "# Lemmatize each word and print lemma\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "I am running along Tancheon which is a small and narrow river for about two hours everyday, praying Christ Jesus to work inside me and help recover from my illness.\n"
     ]
    }
   ],
   "source": [
    "print(type(doc))\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning\n",
    "# We are lemmatizing and removing the stopwords and non-alphabetic characters from each line of dialogues\n",
    "# Load the English Language Model\n",
    "nlp = spacy.load(name='en_core_web_lg', disable=['parser', 'ner'])     # disabling Named Entity Recognition and syntatic parser for speed\n",
    "\n",
    "def cleaning(doc):\n",
    "    # Lemmaitizes and removes stopwords\n",
    "    # doc needs to be a spacy Doc object\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    # Word2Vec uses context words to learn the vector representations of a target word,\n",
    "    # if a sentence is only one or two words long, the benefit for training is very small\n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer']\n"
     ]
    }
   ],
   "source": [
    "# We first load the default English language model, and then we print the names of the current pipeline components using nlp.pipe_names. \n",
    "# We then add a new component called \"sentencizer\" before the \"parser\" component using nlp.add_pipe(). \n",
    "# Finally, we remove the \"ner\" (named entity recognition) component from the pipeline using nlp.remove_pipe().\n",
    "\n",
    "# Print the current pipeline components\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "# Add a new component called sentencizer before tagger\n",
    "# nlp.add_pipe(\"sentencizer\", before='tagger')\n",
    "\n",
    "# Remove a component from the pipeline\n",
    "# nlp.remove_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-alphabetic characters\n",
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", \" \", str(row)).lower() for row in df['spoken_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[This is the first text., Here comes the second text., And finally, the third text.]\n",
      "\n",
      "This is the first text.\n",
      "This PRON this\n",
      "is AUX be\n",
      "the DET the\n",
      "first ADJ first\n",
      "text NOUN text\n",
      ". PUNCT .\n",
      "\n",
      "Here comes the second text.\n",
      "Here ADV here\n",
      "comes VERB come\n",
      "the DET the\n",
      "second ADJ second\n",
      "text NOUN text\n",
      ". PUNCT .\n",
      "\n",
      "And finally, the third text.\n",
      "And CCONJ and\n",
      "finally ADV finally\n",
      ", PUNCT ,\n",
      "the DET the\n",
      "third ADJ third\n",
      "text NOUN text\n",
      ". PUNCT .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The nlp.pipe() function in spaCy is a convenient way to process a large amount of texts efficiently using a spaCy language model. \n",
    "# It takes in a sequence of texts and applies the processing pipeline to each text in parallel.\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Load the language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define a list of texts to process\n",
    "texts = [\"This is the first text.\", \"Here comes the second text.\", \"And finally, the third text.\"]\n",
    "\n",
    "# Process the texts using nlp.pipe()\n",
    "docs = list(nlp.pipe(texts))\n",
    "print(docs)\n",
    "print()\n",
    "\n",
    "# Access the processed documents\n",
    "for doc in docs:\n",
    "    # Perform any desired operations on each document\n",
    "    print(doc.text)\n",
    "    for token in doc:\n",
    "        print(token.text, token.pos_, token.lemma_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up everything : 1.566 mins\n"
     ]
    }
   ],
   "source": [
    "# Take advantage of spaCy.pipe() method to speed up the cleaning process\n",
    "t = time()\n",
    "\n",
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000)]\n",
    "\n",
    "print(f'Time to clean up everything : {round((time() - t) / 60, 3)} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85952, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the results in a DataFrame to remove missing values and duplicates:\n",
    "df_clean = pd.DataFrame({'clean': txt})\n",
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actually little disease magazine news show nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know sure like talk touch lesson plan teach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>life worth live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poll open end recess case decide thought final...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>victory party slide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean\n",
       "0  actually little disease magazine news show nat...\n",
       "2        know sure like talk touch lesson plan teach\n",
       "3                                    life worth live\n",
       "4  poll open end recess case decide thought final...\n",
       "7                                victory party slide"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using Gensim Phrases package to automatically detect common phrases (bigrams) from a list of sentences.\n",
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85952 85952\n",
      "['hey', 'bartle', 'eeboobely', 'care', 'steak', 'rooney']\n"
     ]
    }
   ],
   "source": [
    "# As Phrases() takes a list of list of words as input:\n",
    "sent = [row.split() for row in df_clean['clean']]\n",
    "\n",
    "print(len(sent), len(df_clean['clean']))\n",
    "print(sent[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:19:15: collecting all words and their counts\n",
      "INFO - 20:19:15: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 20:19:15: PROGRESS: at sentence #10000, processed 63557 words and 52676 word types\n",
      "INFO - 20:19:15: PROGRESS: at sentence #20000, processed 130938 words and 99581 word types\n",
      "INFO - 20:19:15: PROGRESS: at sentence #30000, processed 192957 words and 138111 word types\n",
      "INFO - 20:19:15: PROGRESS: at sentence #40000, processed 249830 words and 172098 word types\n",
      "INFO - 20:19:15: PROGRESS: at sentence #50000, processed 311271 words and 207908 word types\n",
      "INFO - 20:19:15: PROGRESS: at sentence #60000, processed 373578 words and 242908 word types\n",
      "INFO - 20:19:15: PROGRESS: at sentence #70000, processed 436426 words and 277808 word types\n",
      "INFO - 20:19:15: PROGRESS: at sentence #80000, processed 497900 words and 310884 word types\n",
      "INFO - 20:19:15: collected 329570 token types (unigram + bigrams) from a corpus of 537081 words and 85952 sentences\n",
      "INFO - 20:19:15: merged Phrases<329570 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 20:19:15: Phrases lifecycle event {'msg': 'built Phrases<329570 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000> in 0.62s', 'datetime': '2023-06-01T20:19:15.718944', 'gensim': '4.3.1', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# Creates the relevant phrases from the list of sentences:\n",
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:22:53: exporting phrases from Phrases<329570 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 20:22:54: FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<127 phrases, min_count=30, threshold=10.0> from Phrases<329570 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000> in 0.68s', 'datetime': '2023-06-01T20:22:54.590879', 'gensim': '4.3.1', 'python': '3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# The goal of Phraser() is to cut down memory consumption of Phrases(), by discarding model state not strictly needed for the bigram detection task:\n",
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85952\n",
      "['hey', 'bartle', 'eeboobely', 'care', 'steak', 'rooney']\n"
     ]
    }
   ],
   "source": [
    "# Transform the corpus based on the bigrams detected\n",
    "sentences = bigram[sent]\n",
    "\n",
    "print(len(sentences))\n",
    "print(sentences[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29676\n"
     ]
    }
   ],
   "source": [
    "# Most Frequent Words\n",
    "# Mainly a sanity check of the effectiveness of the lemmatization, removal of stopwords, and the addition of bigrams.\n",
    "word_freq = defaultdict(int)\n",
    "\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "\n",
    "print(len(word_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'actually': 422,\n",
       "             'little': 2101,\n",
       "             'disease': 45,\n",
       "             'magazine': 122,\n",
       "             'news': 249,\n",
       "             'show': 214,\n",
       "             'natural': 77,\n",
       "             'think': 3593,\n",
       "             'know': 4821,\n",
       "             'sure': 1198,\n",
       "             'like': 5598,\n",
       "             'talk': 937,\n",
       "             'touch': 192,\n",
       "             'lesson': 162,\n",
       "             'plan': 302,\n",
       "             'teach': 324,\n",
       "             'life': 1222,\n",
       "             'worth': 141,\n",
       "             'live': 768,\n",
       "             'poll': 20,\n",
       "             'open': 420,\n",
       "             'end': 464,\n",
       "             'recess': 10,\n",
       "             'case': 215,\n",
       "             'decide': 134,\n",
       "             'thought': 120,\n",
       "             'final': 105,\n",
       "             'statement': 21,\n",
       "             'martin': 120,\n",
       "             'victory': 30,\n",
       "             'party': 421,\n",
       "             'slide': 48,\n",
       "             'mr': 797,\n",
       "             'bergstrom': 17,\n",
       "             'hey': 3620,\n",
       "             'move': 165,\n",
       "             'morning': 238,\n",
       "             'new': 1325,\n",
       "             'job': 589,\n",
       "             'take': 903,\n",
       "             'copernicus': 5,\n",
       "             'costume': 64,\n",
       "             'train': 132,\n",
       "             'capital_city': 40,\n",
       "             'traditional': 19,\n",
       "             'environmentally': 3,\n",
       "             'sound': 298,\n",
       "             'yes': 1128,\n",
       "             'backbone': 7,\n",
       "             'country': 243,\n",
       "             'leland': 1,\n",
       "             'stanford': 4,\n",
       "             'drive': 435,\n",
       "             'golden': 53,\n",
       "             'spike': 15,\n",
       "             'promontory': 1,\n",
       "             'point': 377,\n",
       "             'thank': 1276,\n",
       "             'vote': 164,\n",
       "             'man': 2498,\n",
       "             'voting': 9,\n",
       "             'geek': 21,\n",
       "             'get': 4213,\n",
       "             'right': 3411,\n",
       "             'girl': 674,\n",
       "             'sweat': 35,\n",
       "             'long': 806,\n",
       "             'couple': 202,\n",
       "             'people': 1527,\n",
       "             'milhouse': 502,\n",
       "             'recount': 3,\n",
       "             'want': 3181,\n",
       "             'way': 1678,\n",
       "             'mister': 111,\n",
       "             'president': 261,\n",
       "             'board': 85,\n",
       "             'track': 75,\n",
       "             'afternoon': 87,\n",
       "             'delight': 16,\n",
       "             'come': 3583,\n",
       "             'shelbyville': 85,\n",
       "             'parkville': 1,\n",
       "             'oh': 6453,\n",
       "             'mean': 1259,\n",
       "             'go': 2527,\n",
       "             'leave': 1052,\n",
       "             'ah': 841,\n",
       "             'sorry': 1228,\n",
       "             'lisa': 1725,\n",
       "             'substitute': 24,\n",
       "             'teacher': 219,\n",
       "             'fraud': 30,\n",
       "             'today': 739,\n",
       "             'wear': 395,\n",
       "             'gym': 53,\n",
       "             'short': 163,\n",
       "             'tomorrow': 358,\n",
       "             'speak': 240,\n",
       "             'french': 88,\n",
       "             'pretend': 93,\n",
       "             'run': 578,\n",
       "             'band': 150,\n",
       "             'see': 914,\n",
       "             'god': 623,\n",
       "             'true': 333,\n",
       "             'lie': 370,\n",
       "             'good': 2923,\n",
       "             'need': 1824,\n",
       "             'project': 90,\n",
       "             'problem': 447,\n",
       "             'middle': 94,\n",
       "             'class': 324,\n",
       "             'anybody': 132,\n",
       "             'care': 544,\n",
       "             'abandon': 47,\n",
       "             'understand': 294,\n",
       "             'miss': 591,\n",
       "             'feel': 1048,\n",
       "             'rely': 8,\n",
       "             'guess': 721,\n",
       "             'mind': 393,\n",
       "             'alongside': 4,\n",
       "             'speed': 64,\n",
       "             'goodbye': 152,\n",
       "             'honey': 509,\n",
       "             'okay': 1876,\n",
       "             'read': 478,\n",
       "             'note': 100,\n",
       "             'throw': 365,\n",
       "             'big': 1146,\n",
       "             'bash': 20,\n",
       "             'champagne': 33,\n",
       "             'musician': 24,\n",
       "             'holy': 89,\n",
       "             'bart': 2685,\n",
       "             'bad': 1042,\n",
       "             'thing': 2067,\n",
       "             'happen': 675,\n",
       "             'alright': 52,\n",
       "             'allright': 2,\n",
       "             'spill': 37,\n",
       "             'milk': 124,\n",
       "             'mopey': 1,\n",
       "             'tell': 1863,\n",
       "             'father': 658,\n",
       "             'glad': 216,\n",
       "             'cry': 157,\n",
       "             'hate': 445,\n",
       "             'base': 95,\n",
       "             'emotion': 17,\n",
       "             'sir': 897,\n",
       "             'baboon': 16,\n",
       "             'realize': 181,\n",
       "             'say': 1597,\n",
       "             'whoa': 299,\n",
       "             'somebody': 199,\n",
       "             'bind': 30,\n",
       "             'day': 1761,\n",
       "             'believe': 718,\n",
       "             'hear': 994,\n",
       "             'marge': 2332,\n",
       "             'call': 585,\n",
       "             'stupidest': 1,\n",
       "             'ugly': 115,\n",
       "             'smelly': 11,\n",
       "             'ape': 53,\n",
       "             'homer': 2932,\n",
       "             'allow': 120,\n",
       "             'hurt': 310,\n",
       "             'feeling': 188,\n",
       "             'little_girl': 144,\n",
       "             'upstairs': 32,\n",
       "             'confidence': 25,\n",
       "             'shake': 108,\n",
       "             'happy': 579,\n",
       "             'faith': 73,\n",
       "             'daddy': 328,\n",
       "             'hold': 458,\n",
       "             'look': 3382,\n",
       "             'forgive': 119,\n",
       "             'maybe': 1039,\n",
       "             'help': 1052,\n",
       "             'lose': 622,\n",
       "             'special': 338,\n",
       "             'lucky': 153,\n",
       "             'roof': 60,\n",
       "             'child': 788,\n",
       "             'time': 2559,\n",
       "             'bed': 274,\n",
       "             'lot': 819,\n",
       "             'probably': 212,\n",
       "             'place': 810,\n",
       "             'food': 378,\n",
       "             'real': 665,\n",
       "             'guy': 1581,\n",
       "             'serve': 114,\n",
       "             'drink': 418,\n",
       "             'explain': 112,\n",
       "             'fix': 147,\n",
       "             'doll': 87,\n",
       "             'house': 822,\n",
       "             'monkey': 214,\n",
       "             'work': 1331,\n",
       "             'nail': 58,\n",
       "             'tail': 44,\n",
       "             'dad': 1913,\n",
       "             'matter': 240,\n",
       "             'son': 936,\n",
       "             'lewis': 23,\n",
       "             'money': 943,\n",
       "             'neat': 21,\n",
       "             'ball': 279,\n",
       "             'world': 789,\n",
       "             'series': 69,\n",
       "             'huh': 556,\n",
       "             'let': 2900,\n",
       "             'baby': 888,\n",
       "             'bottle': 127,\n",
       "             'motto': 8,\n",
       "             'moly': 10,\n",
       "             'parent': 263,\n",
       "             'sleep': 379,\n",
       "             'maggie': 474,\n",
       "             'roll': 216,\n",
       "             'mmm': 143,\n",
       "             'hor': 8,\n",
       "             'doover': 1,\n",
       "             'promise': 264,\n",
       "             'eat': 952,\n",
       "             'go_to': 2524,\n",
       "             'pay': 610,\n",
       "             'friend': 841,\n",
       "             'invite': 101,\n",
       "             'home': 1025,\n",
       "             'mom': 1098,\n",
       "             'witty': 13,\n",
       "             'banter': 2,\n",
       "             'sophisticated': 18,\n",
       "             'adult': 120,\n",
       "             'yeah': 2305,\n",
       "             'fun': 566,\n",
       "             'old': 1084,\n",
       "             'well': 1092,\n",
       "             'hmmm': 177,\n",
       "             'mmmm': 58,\n",
       "             'gag': 31,\n",
       "             'ice': 103,\n",
       "             'cub': 7,\n",
       "             'record': 157,\n",
       "             'bartender': 36,\n",
       "             'ph': 6,\n",
       "             'd': 259,\n",
       "             'mixology': 1,\n",
       "             'try': 1014,\n",
       "             'flander': 372,\n",
       "             'planter': 1,\n",
       "             'punch': 112,\n",
       "             'alcohol': 64,\n",
       "             'au': 14,\n",
       "             'contraire': 3,\n",
       "             'simpson': 960,\n",
       "             'shot': 119,\n",
       "             'rum': 13,\n",
       "             'jigger': 2,\n",
       "             'bourbon': 11,\n",
       "             'dab': 6,\n",
       "             'roo': 3,\n",
       "             'creme': 6,\n",
       "             'de': 193,\n",
       "             'cassis': 1,\n",
       "             'flavor': 44,\n",
       "             'warm': 91,\n",
       "             'sense': 122,\n",
       "             'ssslurre': 1,\n",
       "             'shpeech': 1,\n",
       "             'easy': 337,\n",
       "             'al': 48,\n",
       "             'ky': 2,\n",
       "             'hol': 2,\n",
       "             'remember': 691,\n",
       "             'year': 984,\n",
       "             'winfield': 3,\n",
       "             'laundry': 35,\n",
       "             'hamper': 7,\n",
       "             'hi': 379,\n",
       "             'sister': 280,\n",
       "             'law': 206,\n",
       "             'beau': 4,\n",
       "             'tiful': 2,\n",
       "             'ow': 196,\n",
       "             'jeez': 32,\n",
       "             'kind': 553,\n",
       "             'mace': 6,\n",
       "             'painful': 20,\n",
       "             'dr_hibbert': 46,\n",
       "             'enjoy': 319,\n",
       "             'uh': 2381,\n",
       "             'slip': 66,\n",
       "             'novelty': 26,\n",
       "             'cube': 40,\n",
       "             'fake': 115,\n",
       "             'fly': 258,\n",
       "             'highly': 51,\n",
       "             'toxic': 18,\n",
       "             'chemical': 23,\n",
       "             'ironically': 11,\n",
       "             'sanitary': 4,\n",
       "             'face': 521,\n",
       "             'priceless': 22,\n",
       "             'cute': 128,\n",
       "             'everybody': 434,\n",
       "             'funny': 322,\n",
       "             'king': 213,\n",
       "             'wantin': 5,\n",
       "             \"'\": 2779,\n",
       "             'nerve': 19,\n",
       "             'wife': 525,\n",
       "             'meet': 480,\n",
       "             'hour': 422,\n",
       "             'ago': 129,\n",
       "             'stink': 112,\n",
       "             'lousy': 131,\n",
       "             'operation': 59,\n",
       "             'quit': 223,\n",
       "             'gee': 127,\n",
       "             'handful': 11,\n",
       "             'peanut': 71,\n",
       "             'maude': 80,\n",
       "             'invitin': 2,\n",
       "             'wonderful': 221,\n",
       "             'night': 813,\n",
       "             'suggest': 50,\n",
       "             'kid': 1903,\n",
       "             'young': 314,\n",
       "             'fight': 375,\n",
       "             'music': 262,\n",
       "             'send': 365,\n",
       "             'chill': 28,\n",
       "             'spine': 22,\n",
       "             'act': 250,\n",
       "             'wet': 78,\n",
       "             'clothe': 118,\n",
       "             'dry': 86,\n",
       "             'martini': 9,\n",
       "             'good_lord': 61,\n",
       "             'glass': 160,\n",
       "             'pronounce': 29,\n",
       "             'whimsical': 3,\n",
       "             'jape': 3,\n",
       "             'season': 91,\n",
       "             'patient': 30,\n",
       "             'tolerant': 5,\n",
       "             'woman': 590,\n",
       "             'line': 288,\n",
       "             'cross': 92,\n",
       "             'stop': 1075,\n",
       "             'love': 1880,\n",
       "             'forget': 515,\n",
       "             'church': 206,\n",
       "             'stay': 519,\n",
       "             'scar': 18,\n",
       "             'inside': 219,\n",
       "             'notice': 117,\n",
       "             'strange': 61,\n",
       "             'admit': 113,\n",
       "             'hope': 504,\n",
       "             'respect': 129,\n",
       "             'sneak': 66,\n",
       "             'preview': 10,\n",
       "             'week': 468,\n",
       "             'sermon': 22,\n",
       "             'announcement': 43,\n",
       "             'pamphlet': 19,\n",
       "             'available': 35,\n",
       "             'newsrack': 1,\n",
       "             'include': 80,\n",
       "             'bible': 95,\n",
       "             'bafflers': 1,\n",
       "             'satan': 46,\n",
       "             'boner': 11,\n",
       "             'grief': 13,\n",
       "             'teen': 44,\n",
       "             'cool': 485,\n",
       "             'fry': 85,\n",
       "             'hell': 420,\n",
       "             'lord': 211,\n",
       "             'compete': 23,\n",
       "             'squeaking': 1,\n",
       "             'homer_simpson': 423,\n",
       "             'shoe': 166,\n",
       "             'seat': 163,\n",
       "             'mrs': 148,\n",
       "             'lovejoy': 67,\n",
       "             'annual': 40,\n",
       "             'marriage': 225,\n",
       "             'retreat': 12,\n",
       "             'weekend': 97,\n",
       "             'catfish': 10,\n",
       "             'lake': 44,\n",
       "             'psychological': 9,\n",
       "             'counseling': 11,\n",
       "             'hang': 226,\n",
       "             'thread': 12,\n",
       "             'tune': 59,\n",
       "             'wish': 412,\n",
       "             'participate': 16,\n",
       "             'sign': 308,\n",
       "             'service': 130,\n",
       "             'attend': 29,\n",
       "             'tempting': 6,\n",
       "             'idea': 426,\n",
       "             'encounter': 10,\n",
       "             'fishing': 19,\n",
       "             'hello': 623,\n",
       "             'mrs_simpson': 116,\n",
       "             'suppose': 346,\n",
       "             'sitter': 23,\n",
       "             'dear': 300,\n",
       "             'find': 1264,\n",
       "             'babysitter': 28,\n",
       "             'kick': 187,\n",
       "             'tooth': 163,\n",
       "             'half': 287,\n",
       "             'tone': 25,\n",
       "             'young_lady': 39,\n",
       "             'taste': 165,\n",
       "             'hand': 583,\n",
       "             'wonder': 256,\n",
       "             'babysit': 7,\n",
       "             'ask': 567,\n",
       "             'desperate': 33,\n",
       "             'resort': 21,\n",
       "             'grampa': 270,\n",
       "             'feeb': 2,\n",
       "             'count': 138,\n",
       "             'dagnabit': 4,\n",
       "             'agin': 2,\n",
       "             'puttin': 17,\n",
       "             'trunk': 29,\n",
       "             'fever': 38,\n",
       "             'number': 369,\n",
       "             'stick': 302,\n",
       "             'finger': 124,\n",
       "             'electrical': 14,\n",
       "             'socket': 4,\n",
       "             'pine': 24,\n",
       "             'cleanser': 5,\n",
       "             'behave': 26,\n",
       "             'fall': 288,\n",
       "             'bathtub': 16,\n",
       "             'hurry': 113,\n",
       "             'list': 111,\n",
       "             'uh_huh': 124,\n",
       "             'smoke': 135,\n",
       "             'cigar': 24,\n",
       "             'gas': 155,\n",
       "             'fill': 213,\n",
       "             'er': 85,\n",
       "             'stretch': 31,\n",
       "             'leg': 166,\n",
       "             'general': 51,\n",
       "             'sherman': 20,\n",
       "             'ya': 873,\n",
       "             'wait_wait': 98,\n",
       "             'minute': 445,\n",
       "             'wait_minute': 319,\n",
       "             'part': 40,\n",
       "             'weigh': 30,\n",
       "             'upwards': 4,\n",
       "             'pound': 113,\n",
       "             'picture': 276,\n",
       "             'exactly': 175,\n",
       "             'freakishly': 2,\n",
       "             'hmmmm': 11,\n",
       "             'gentleman': 152,\n",
       "             'catch': 296,\n",
       "             'supermarket': 16,\n",
       "             'video': 123,\n",
       "             'store': 315,\n",
       "             'grab': 89,\n",
       "             'krusty': 559,\n",
       "             'burger': 54,\n",
       "             'head': 641,\n",
       "             'arcade': 8,\n",
       "             'kindly': 20,\n",
       "             'old_man': 152,\n",
       "             'trust': 145,\n",
       "             'advantage': 35,\n",
       "             'lis': 199,\n",
       "             'crazy': 381,\n",
       "             'topsy': 3,\n",
       "             'turvy': 3,\n",
       "             'wrong': 486,\n",
       "             'gut': 63,\n",
       "             'bleed': 34,\n",
       "             'gramp': 3,\n",
       "             'welcome': 444,\n",
       "             'reverend': 96,\n",
       "             'helen': 52,\n",
       "             'hel': 25,\n",
       "             'lo': 38,\n",
       "             'spit': 65,\n",
       "             'shine': 64,\n",
       "             'chance': 232,\n",
       "             'afraid': 356,\n",
       "             'reconcile': 2,\n",
       "             'bait': 16,\n",
       "             'hook': 71,\n",
       "             'honesty': 14,\n",
       "             'will': 753,\n",
       "             'away': 678,\n",
       "             'bowling': 60,\n",
       "             'expression': 27,\n",
       "             'turnout': 4,\n",
       "             'room': 480,\n",
       "             'introduce': 57,\n",
       "             'little_bit': 57,\n",
       "             'john': 110,\n",
       "             'gloria': 13,\n",
       "             'johnny': 51,\n",
       "             'boy': 1860,\n",
       "             'able': 112,\n",
       "             'cut': 411,\n",
       "             'manwise': 1,\n",
       "             'odor': 14,\n",
       "             'gin': 12,\n",
       "             'sour': 23,\n",
       "             'defeat': 36,\n",
       "             'press': 81,\n",
       "             'cook': 86,\n",
       "             'keep': 192,\n",
       "             'filthy': 39,\n",
       "             'profanely': 1,\n",
       "             'queen': 108,\n",
       "             'harpy': 1,\n",
       "             'eye': 574,\n",
       "             'beautiful': 343,\n",
       "             'save': 565,\n",
       "             'bring': 684,\n",
       "             'happiness': 50,\n",
       "             'pass': 267,\n",
       "             'collection': 52,\n",
       "             'plate': 71,\n",
       "             'ned': 202,\n",
       "             'god_bless': 35,\n",
       "             'underline': 3,\n",
       "             'passage': 10,\n",
       "             'gun': 208,\n",
       "             'ohhh': 79,\n",
       "             'drunk': 152,\n",
       "             'dress': 159,\n",
       "             'fault': 144,\n",
       "             'interrupt': 34,\n",
       "             'turn': 825,\n",
       "             'self': 123,\n",
       "             'center': 126,\n",
       "             'birthday': 180,\n",
       "             'anniversary': 49,\n",
       "             'holiday': 62,\n",
       "             'religious': 29,\n",
       "             'secular': 3,\n",
       "             'chew': 73,\n",
       "             'mouth': 199,\n",
       "             'gamble': 33,\n",
       "             'seedy': 2,\n",
       "             'bar': 334,\n",
       "             'bum': 61,\n",
       "             'lowlife': 2,\n",
       "             'blow': 252,\n",
       "             'nose': 142,\n",
       "             'towel': 48,\n",
       "             'put': 110,\n",
       "             'gallon': 17,\n",
       "             'chocolate': 112,\n",
       "             'brownie': 21,\n",
       "             'fudge': 32,\n",
       "             'chip': 84,\n",
       "             'write': 466,\n",
       "             'shopping': 38,\n",
       "             'aisle': 21,\n",
       "             'step': 188,\n",
       "             'carton': 13,\n",
       "             'change': 487,\n",
       "             'make': 719,\n",
       "             'chewing': 3,\n",
       "             'noise': 64,\n",
       "             'wake': 182,\n",
       "             'honking': 2,\n",
       "             'scratch': 46,\n",
       "             'key': 168,\n",
       "             'wait': 767,\n",
       "             'toenail': 6,\n",
       "             'yellow': 72,\n",
       "             'tired': 142,\n",
       "             'chest': 37,\n",
       "             'luau': 3,\n",
       "             'mcbain': 32,\n",
       "             'cannon': 21,\n",
       "             'regulation': 9,\n",
       "             'department': 61,\n",
       "             'book': 529,\n",
       "             \"gettin_'\": 143,\n",
       "             'pretty': 458,\n",
       "             'late': 291,\n",
       "             'use': 646,\n",
       "             'have': 330,\n",
       "             'ethical': 5,\n",
       "             'crisis': 36,\n",
       "             'thirty': 226,\n",
       "             'clean': 291,\n",
       "             'seven': 279,\n",
       "             'incriminate': 5,\n",
       "             'evidence': 41,\n",
       "             'perfect': 288,\n",
       "             'crime': 125,\n",
       "             'fish': 177,\n",
       "             'selfishness': 2,\n",
       "             'anytime': 18,\n",
       "             'honest': 99,\n",
       "             'walk': 348,\n",
       "             'get_to': 851,\n",
       "             'husband': 307,\n",
       "             'forgot': 31,\n",
       "             'ahead': 148,\n",
       "             'waste': 165,\n",
       "             'strength': 38,\n",
       "             'skillet': 1,\n",
       "             'butter': 68,\n",
       "             'ma': 96,\n",
       "             'coffee': 129,\n",
       "             'blowout': 2,\n",
       "             'casa': 3,\n",
       "             'frail': 2,\n",
       "             'joint': 23,\n",
       "             'twoish': 1,\n",
       "             'square': 95,\n",
       "             'funky': 15,\n",
       "             'noon': 20,\n",
       "             'exercise': 51,\n",
       "             'backwards': 33,\n",
       "             'spouse': 6,\n",
       "             'recommend': 28,\n",
       "             'counselor': 21,\n",
       "             'instance': 7,\n",
       "             'partner': 75,\n",
       "             'percent': 99,\n",
       "             'willing': 37,\n",
       "             'certificate': 16,\n",
       "             'frame': 53,\n",
       "             'word': 540,\n",
       "             'yank': 11,\n",
       "             \"comin_'\": 168,\n",
       "             'famous': 104,\n",
       "             'fisherman': 1,\n",
       "             'bald': 58,\n",
       "             'cable': 60,\n",
       "             'mackerel': 1,\n",
       "             'pal': 112,\n",
       "             'cherry': 28,\n",
       "             'chick': 82,\n",
       "             'obvious': 28,\n",
       "             'degrade': 2,\n",
       "             'set': 307,\n",
       "             'movement': 14,\n",
       "             'decade': 18,\n",
       "             'great': 1386,\n",
       "             'shut': 293,\n",
       "             'door': 276,\n",
       "             'haw_haw': 72,\n",
       "             'haw': 27,\n",
       "             'hellion': 4,\n",
       "             'belt': 67,\n",
       "             'nice': 668,\n",
       "             'tie': 141,\n",
       "             'nelson': 185,\n",
       "             'fail': 121,\n",
       "             'useless': 29,\n",
       "             'strong': 115,\n",
       "             'unpleasant': 12,\n",
       "             'remorse': 7,\n",
       "             'vile': 3,\n",
       "             'burlesque': 12,\n",
       "             'irrepressible': 3,\n",
       "             'youth': 38,\n",
       "             'bucket': 51,\n",
       "             'brush': 42,\n",
       "             'hard': 418,\n",
       "             'fast': 253,\n",
       "             'champion': 42,\n",
       "             'loser': 140,\n",
       "             'cause': 123,\n",
       "             'worlllld': 1,\n",
       "             'trouble': 227,\n",
       "             'expect': 115,\n",
       "             'represent': 47,\n",
       "             'hero': 167,\n",
       "             'weirdo': 21,\n",
       "             'worm': 30,\n",
       "             'selfish': 29,\n",
       "             'wow': 640,\n",
       "             'give': 653,\n",
       "             'fame': 23,\n",
       "             'breakfast': 113,\n",
       "             'toss': 50,\n",
       "             'secret': 272,\n",
       "             'fawcet': 1,\n",
       "             'boo': 72,\n",
       "             'hoo': 67,\n",
       "             'sad': 161,\n",
       "             'person': 198,\n",
       "             'fool': 160,\n",
       "             'sucker': 62,\n",
       "             'hee_hee': 37,\n",
       "             'hee': 21,\n",
       "             'yup': 20,\n",
       "             'dwelling': 1,\n",
       "             'fury': 5,\n",
       "             'fella': 83,\n",
       "             'close': 360,\n",
       "             'foot': 244,\n",
       "             'tall': 54,\n",
       "             'arm': 151,\n",
       "             'tree': 219,\n",
       "             'steel': 27,\n",
       "             'cold': 149,\n",
       "             'shock': 44,\n",
       "             'hair': 331,\n",
       "             'red': 202,\n",
       "             'fire': 435,\n",
       "             'convention': 28,\n",
       "             'soon': 257,\n",
       "             'comic_strip': 43,\n",
       "             'fallout': 22,\n",
       "             'ward': 7,\n",
       "             'buy': 680,\n",
       "             'casper': 5,\n",
       "             'wimpy': 1,\n",
       "             'ghost': 67,\n",
       "             'equate': 1,\n",
       "             'friendliness': 1,\n",
       "             'wimpiness': 2,\n",
       "             'achieve': 25,\n",
       "             'popularity': 13,\n",
       "             'richie': 9,\n",
       "             'rich': 198,\n",
       "             'alike': 15,\n",
       "             'die': 555,\n",
       "             'hollow': 17,\n",
       "             'pursuit': 10,\n",
       "             'lighten': 21,\n",
       "             'radioactive_man': 53,\n",
       "             'rule': 172,\n",
       "             'knock': 148,\n",
       "             'sun': 96,\n",
       "             'hot': 315,\n",
       "             'dressed': 9,\n",
       "             'popular': 101,\n",
       "             'cartoon': 136,\n",
       "             'character': 125,\n",
       "             'discount': 24,\n",
       "             'ahem': 5,\n",
       "             'springfield': 979,\n",
       "             'mayor': 138,\n",
       "             'pump': 50,\n",
       "             'dollar': 424,\n",
       "             'local': 132,\n",
       "             'economy': 26,\n",
       "             'youthful': 11,\n",
       "             'high': 251,\n",
       "             'spirit': 114,\n",
       "             'impart': 5,\n",
       "             'glow': 26,\n",
       "             'war': 200,\n",
       "             'horse': 153,\n",
       "             'radiation': 22,\n",
       "             'jerk': 167,\n",
       "             'stand': 347,\n",
       "             'correct': 50,\n",
       "             'clear': 148,\n",
       "             'shriner': 2,\n",
       "             'punk': 45,\n",
       "             'diamond': 48,\n",
       "             'joe': 131,\n",
       "             'quimby': 77,\n",
       "             'excuse': 306,\n",
       "             'left': 108,\n",
       "             'vulcan': 2,\n",
       "             'ear': 113,\n",
       "             'utility': 15,\n",
       "             'tricorder': 1,\n",
       "             'light': 271,\n",
       "             'saber': 9,\n",
       "             'dude': 198,\n",
       "             'otto': 79,\n",
       "             'oooh': 137,\n",
       "             'comic_book': 77,\n",
       "             'school': 952,\n",
       "             'bus': 196,\n",
       "             'vampire': 47,\n",
       "             'post': 65,\n",
       "             'apocalyptic': 2,\n",
       "             'warzone': 1,\n",
       "             'buddy': 143,\n",
       "             'hodge': 2,\n",
       "             'play': 849,\n",
       "             'tv': 416,\n",
       "             'kill': 751,\n",
       "             'vietnam': 18,\n",
       "             'aaahh': 1,\n",
       "             'laramie': 15,\n",
       "             'cigarette': 69,\n",
       "             'steady': 23,\n",
       "             'combat': 13,\n",
       "             'evil': 139,\n",
       "             'whillikers': 1,\n",
       "             'wisht': 1,\n",
       "             'sixteen': 33,\n",
       "             'earth': 181,\n",
       "             \"y'know\": 87,\n",
       "             'actor': 50,\n",
       "             'dirk': 4,\n",
       "             'richter': 4,\n",
       "             'portrayal': 1,\n",
       "             'sordid': 6,\n",
       "             'detail': 26,\n",
       "             'question': 309,\n",
       "             'tasteful': 5,\n",
       "             'inject': 11,\n",
       "             'shrink': 12,\n",
       "             'serum': 3,\n",
       "             'issue': 74,\n",
       "             'finish': 182,\n",
       "             'tum': 6,\n",
       "             'tugger': 1,\n",
       "             'second': 406,\n",
       "             'national': 69,\n",
       "             'tour': 93,\n",
       "             'company': 168,\n",
       "             'cat': 238,\n",
       "             'ooh_ooh': 34,\n",
       "             'masked': 1,\n",
       "             'haunt': 19,\n",
       "             'bordello': 3,\n",
       "             'bullet': 57,\n",
       "             'riddled': 1,\n",
       "             'body': 204,\n",
       "             'vulture': 8,\n",
       "             'seventy': 89,\n",
       "             'imaginary': 21,\n",
       "             'tale': 57,\n",
       "             'marry': 299,\n",
       "             'larva': 2,\n",
       "             'grubby': 2,\n",
       "             'them': 545,\n",
       "             'bet': 244,\n",
       "             'million': 156,\n",
       "             'buck': 211,\n",
       "             'lad': 35,\n",
       "             'remind': 122,\n",
       "             'moment': 207,\n",
       "             'sell': 389,\n",
       "             'dozen': 27,\n",
       "             'lois': 7,\n",
       "             'lane': 32,\n",
       "             'superman': 26,\n",
       "             'lariat': 1,\n",
       "             'dinner': 302,\n",
       "             'treat': 137,\n",
       "             'sport': 133,\n",
       "             'fine': 535,\n",
       "             'restaurant': 86,\n",
       "             'draw': 101,\n",
       "             'micha': 1,\n",
       "             'langelo': 1,\n",
       "             'usually': 93,\n",
       "             'bug': 105,\n",
       "             'mad': 224,\n",
       "             'pay_attention': 48,\n",
       "             'win': 628,\n",
       "             'apple': 133,\n",
       "             'woo_hoo': 202,\n",
       "             'gloat': 2,\n",
       "             'age': 171,\n",
       "             'sized': 13,\n",
       "             'electric': 64,\n",
       "             'lightbulb': 4,\n",
       "             'oven': 31,\n",
       "             'patty_selma': 31,\n",
       "             'slave': 37,\n",
       "             'free': 523,\n",
       "             'smoking': 22,\n",
       "             'month': 246,\n",
       "             'venus': 14,\n",
       "             'shield': 11,\n",
       "             'wash': 115,\n",
       "             'drip': 12,\n",
       "             'finally': 355,\n",
       "             'extra': 169,\n",
       "             'answer': 297,\n",
       "             'aw': 464,\n",
       "             'stupid': 592,\n",
       "             'piece': 174,\n",
       "             'childhood': 31,\n",
       "             'forever': 223,\n",
       "             'ahh': 72,\n",
       "             'ooh': 520,\n",
       "             'deposit': 21,\n",
       "             'defray': 1,\n",
       "             'cost': 144,\n",
       "             'jumbo': 19,\n",
       "             'squishie': 1,\n",
       "             'dime': 26,\n",
       "             'learn': 484,\n",
       "             'trade': 67,\n",
       "             'americanize': 1,\n",
       "             'coin': 37,\n",
       "             'cent': 122,\n",
       "             'humiliating': 10,\n",
       "             'terrible': 174,\n",
       "             'car': 692,\n",
       "             'slow': 106,\n",
       "             'laugh': 242,\n",
       "             'buying': 5,\n",
       "             'sympathy': 5,\n",
       "             'ha': 164,\n",
       "             'pathetic': 43,\n",
       "             'lemonade': 27,\n",
       "             'suck': 208,\n",
       "             'product': 66,\n",
       "             'form': 128,\n",
       "             'crowding': 1,\n",
       "             'cheap': 84,\n",
       "             'beer': 501,\n",
       "             'sympathetic': 3,\n",
       "             'credit': 78,\n",
       "             'liquor': 42,\n",
       "             'license': 72,\n",
       "             'ugh': 56,\n",
       "             'dog': 648,\n",
       "             'ticket': 217,\n",
       "             'thirsty': 13,\n",
       "             'ell': 3,\n",
       "             'offense': 28,\n",
       "             'officer': 66,\n",
       "             'poor': 227,\n",
       "             'earn': 81,\n",
       "             'nazi': 12,\n",
       "             'smasher': 2,\n",
       "             'chore': 26,\n",
       "             'mix': 70,\n",
       "             'whitewash': 4,\n",
       "             'eh': 491,\n",
       "             'burt': 12,\n",
       "             'apricot': 2,\n",
       "             'almond': 12,\n",
       "             'paste': 14,\n",
       "             'sauerkraut': 4,\n",
       "             'candy': 192,\n",
       "             'brother': 315,\n",
       "             'asa': 7,\n",
       "             'grenade': 6,\n",
       "             'kaiser': 4,\n",
       "             'bill': 215,\n",
       "             'delivery': 41,\n",
       "             'uncle': 90,\n",
       "             'sam': 20,\n",
       "             'harrison': 6,\n",
       "             'brooklyn': 9,\n",
       "             'bob': 166,\n",
       "             'reggie': 3,\n",
       "             'be': 357,\n",
       "             'stuck': 56,\n",
       "             'ribbon': 24,\n",
       "             \"ma'am\": 88,\n",
       "             'start': 788,\n",
       "             'yard': 84,\n",
       "             'barley': 3,\n",
       "             'pop': 135,\n",
       "             'weed': 11,\n",
       "             'one': 133,\n",
       "             'careful': 72,\n",
       "             'watch': 700,\n",
       "             'story': 431,\n",
       "             'genuinely': 1,\n",
       "             'arouse': 4,\n",
       "             'merciful': 6,\n",
       "             'heaven': 131,\n",
       "             'iodine': 3,\n",
       "             'listen': 599,\n",
       "             'lady': 450,\n",
       "             'yaaauuuuggghhh': 1,\n",
       "             'glick': 7,\n",
       "             'sludge': 5,\n",
       "             'certainly': 108,\n",
       "             'collect': 49,\n",
       "             'downspout': 1,\n",
       "             'bat': 60,\n",
       "             'beulah': 2,\n",
       "             'wedding': 186,\n",
       "             'dye': 21,\n",
       "             ...})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh', 'like', 'know', 'get', 'hey', 'think', 'come', 'right', 'look', 'want']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"'\", 2779), (\"'_n\", 53), (\"'_til\", 82), (\"'_tis\", 35), (\"'bout\", 168), (\"'cause\", 470), (\"'cuz\", 7), (\"a'hind\", 1), (\"a'ight\", 2), (\"a'twain\", 1)]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "word_freq_by_key = sorted(word_freq.items(), key=operator.itemgetter(0), reverse=False)[:10]\n",
    "print(word_freq_by_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('oh', 6453), ('like', 5598), ('know', 4821), ('get', 4213), ('hey', 3620), ('think', 3593), ('come', 3583), ('right', 3411), ('look', 3382), ('want', 3181)]\n"
     ]
    }
   ],
   "source": [
    "word_freq_by_value = sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)[:10]\n",
    "print(word_freq_by_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
